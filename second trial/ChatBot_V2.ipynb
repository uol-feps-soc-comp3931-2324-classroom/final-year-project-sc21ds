{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7739073,"sourceType":"datasetVersion","datasetId":4519611}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install langchain langchain-community langchain-openai chromadb jq langchainhub","metadata":{"execution":{"iopub.status.busy":"2024-03-02T05:21:43.872586Z","iopub.execute_input":"2024-03-02T05:21:43.873027Z","iopub.status.idle":"2024-03-02T05:22:46.390249Z","shell.execute_reply.started":"2024-03-02T05:21:43.872993Z","shell.execute_reply":"2024-03-02T05:22:46.388706Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting langchain\n  Downloading langchain-0.1.10-py3-none-any.whl.metadata (13 kB)\nCollecting langchain-community\n  Downloading langchain_community-0.0.25-py3-none-any.whl.metadata (8.1 kB)\nCollecting langchain-openai\n  Downloading langchain_openai-0.0.8-py3-none-any.whl.metadata (2.5 kB)\nCollecting chromadb\n  Downloading chromadb-0.4.24-py3-none-any.whl.metadata (7.3 kB)\nCollecting jq\n  Downloading jq-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\nCollecting langchainhub\n  Downloading langchainhub-0.1.14-py3-none-any.whl.metadata (478 bytes)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.4)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.33)\nCollecting langchain-core<0.2,>=0.1.28 (from langchain)\n  Downloading langchain_core-0.1.28-py3-none-any.whl.metadata (6.0 kB)\nCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\nCollecting langsmith<0.2.0,>=0.1.0 (from langchain)\n  Downloading langsmith-0.1.13-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\nCollecting openai<2.0.0,>=1.10.0 (from langchain-openai)\n  Downloading openai-1.13.3-py3-none-any.whl.metadata (18 kB)\nCollecting tiktoken<1,>=0.5.2 (from langchain-openai)\n  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\nCollecting build>=1.0.3 (from chromadb)\n  Downloading build-1.1.1-py3-none-any.whl.metadata (4.2 kB)\nCollecting chroma-hnswlib==0.7.3 (from chromadb)\n  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\nRequirement already satisfied: fastapi>=0.95.2 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.108.0)\nRequirement already satisfied: uvicorn>=0.18.3 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.25.0)\nCollecting posthog>=2.4.0 (from chromadb)\n  Downloading posthog-3.4.2-py2.py3-none-any.whl.metadata (2.0 kB)\nRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (4.9.0)\nCollecting pulsar-client>=3.1.0 (from chromadb)\n  Downloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.0 kB)\nCollecting onnxruntime>=1.14.1 (from chromadb)\n  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\nRequirement already satisfied: opentelemetry-api>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.22.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.22.0)\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n  Downloading opentelemetry_instrumentation_fastapi-0.44b0-py3-none-any.whl.metadata (2.3 kB)\nRequirement already satisfied: opentelemetry-sdk>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.22.0)\nRequirement already satisfied: tokenizers>=0.13.2 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.15.2)\nCollecting pypika>=0.48.9 (from chromadb)\n  Downloading PyPika-0.48.9.tar.gz (67 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (4.66.1)\nRequirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.10/site-packages (from chromadb) (7.4.0)\nRequirement already satisfied: importlib-resources in /opt/conda/lib/python3.10/site-packages (from chromadb) (6.1.1)\nRequirement already satisfied: grpcio>=1.58.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (1.60.0)\nCollecting bcrypt>=4.0.1 (from chromadb)\n  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.5 kB)\nRequirement already satisfied: typer>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from chromadb) (0.9.0)\nCollecting kubernetes>=28.1.0 (from chromadb)\n  Downloading kubernetes-29.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: mmh3>=4.0.1 in /opt/conda/lib/python3.10/site-packages (from chromadb) (4.1.0)\nCollecting orjson>=3.9.12 (from chromadb)\n  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n  Downloading types_requests-2.31.0.20240218-py3-none-any.whl.metadata (1.8 kB)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: packaging>=19.0 in /opt/conda/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (21.3)\nCollecting pyproject_hooks (from build>=1.0.3->chromadb)\n  Downloading pyproject_hooks-1.0.0-py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: tomli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from build>=1.0.3->chromadb) (2.0.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: starlette<0.33.0,>=0.29.0 in /opt/conda/lib/python3.10/site-packages (from fastapi>=0.95.2->chromadb) (0.32.0.post1)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\nRequirement already satisfied: certifi>=14.05.14 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\nRequirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\nRequirement already satisfied: google-auth>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (2.26.1)\nRequirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\nRequirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\nRequirement already satisfied: oauthlib>=3.2.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\nRequirement already satisfied: urllib3>=1.24.2 in /opt/conda/lib/python3.10/site-packages (from kubernetes>=28.1.0->chromadb) (1.26.18)\nRequirement already satisfied: anyio<5,>=3 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.2,>=0.1.28->langchain) (4.2.0)\nCollecting packaging>=19.0 (from build>=1.0.3->chromadb)\n  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\nRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (0.27.0)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from openai<2.0.0,>=1.10.0->langchain-openai) (1.3.0)\nRequirement already satisfied: deprecated>=1.2.6 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\nRequirement already satisfied: importlib-metadata<7.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.2.0->chromadb) (6.11.0)\nRequirement already satisfied: backoff<3.0.0,>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (2.2.1)\nRequirement already satisfied: googleapis-common-protos~=1.52 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.62.0)\nRequirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.22.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.22.0)\nRequirement already satisfied: opentelemetry-proto==1.22.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.22.0)\nCollecting opentelemetry-instrumentation-asgi==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation_asgi-0.44b0-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation-0.44b0-py3-none-any.whl.metadata (6.1 kB)\nCollecting opentelemetry-semantic-conventions==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_semantic_conventions-0.44b0-py3-none-any.whl.metadata (2.2 kB)\nCollecting opentelemetry-util-http==0.44b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_util_http-0.44b0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: setuptools>=16.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (69.0.3)\nRequirement already satisfied: wrapt<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\nCollecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.44b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading asgiref-3.7.2-py3-none-any.whl.metadata (9.2 kB)\nINFO: pip is looking at multiple versions of opentelemetry-sdk to determine which version is compatible with other requirements. This could take a while.\nCollecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n  Downloading opentelemetry_instrumentation_fastapi-0.43b0-py3-none-any.whl.metadata (2.3 kB)\nCollecting opentelemetry-instrumentation-asgi==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation_asgi-0.43b0-py3-none-any.whl.metadata (2.1 kB)\nCollecting opentelemetry-instrumentation==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_instrumentation-0.43b0-py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: opentelemetry-semantic-conventions==0.43b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\nCollecting opentelemetry-util-http==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n  Downloading opentelemetry_util_http-0.43b0-py3-none-any.whl.metadata (2.5 kB)\nCollecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken<1,>=0.5.2->langchain-openai) (2023.12.25)\nRequirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\nCollecting urllib3>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n  Downloading urllib3-2.2.1-py3-none-any.whl.metadata (6.4 kB)\nRequirement already satisfied: h11>=0.8 in /opt/conda/lib/python3.10/site-packages (from uvicorn>=0.18.3->uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\nRequirement already satisfied: httptools>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\nRequirement already satisfied: python-dotenv>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\nRequirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\nRequirement already satisfied: watchfiles>=0.13 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\nRequirement already satisfied: websockets>=10.4 in /opt/conda/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.28->langchain) (1.2.0)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain-openai) (1.0.4)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.2.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\nDownloading langchain-0.1.10-py3-none-any.whl (806 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m806.2/806.2 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading langchain_community-0.0.25-py3-none-any.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading langchain_openai-0.0.8-py3-none-any.whl (32 kB)\nDownloading chromadb-0.4.24-py3-none-any.whl (525 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading jq-1.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (656 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m656.0/656.0 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchainhub-0.1.14-py3-none-any.whl (3.4 kB)\nDownloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading build-1.1.1-py3-none-any.whl (19 kB)\nDownloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading langchain_core-0.1.28-py3-none-any.whl (252 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.4/252.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\nDownloading langsmith-0.1.13-py3-none-any.whl (64 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading openai-1.13.3-py3-none-any.whl (227 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.43b0-py3-none-any.whl (11 kB)\nDownloading opentelemetry_instrumentation_asgi-0.43b0-py3-none-any.whl (14 kB)\nDownloading opentelemetry_instrumentation-0.43b0-py3-none-any.whl (28 kB)\nDownloading opentelemetry_util_http-0.43b0-py3-none-any.whl (6.9 kB)\nDownloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading posthog-3.4.2-py2.py3-none-any.whl (41 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading types_requests-2.31.0.20240218-py3-none-any.whl (14 kB)\nDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\nDownloading packaging-23.2-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyproject_hooks-1.0.0-py3-none-any.whl (9.3 kB)\nDownloading asgiref-3.7.2-py3-none-any.whl (24 kB)\nDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: pypika\n  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=45b4a5de1f949c7908cf7ab145421d4900fee16483947a6d3ecec4a995267675\n  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\nSuccessfully built pypika\nInstalling collected packages: pypika, monotonic, urllib3, pyproject_hooks, pulsar-client, packaging, orjson, opentelemetry-util-http, jq, humanfriendly, chroma-hnswlib, bcrypt, asgiref, types-requests, coloredlogs, build, tiktoken, posthog, opentelemetry-instrumentation, openai, onnxruntime, langsmith, langchainhub, opentelemetry-instrumentation-asgi, langchain-core, kubernetes, opentelemetry-instrumentation-fastapi, langchain-text-splitters, langchain-openai, langchain-community, langchain, chromadb\n  Attempting uninstall: urllib3\n    Found existing installation: urllib3 1.26.18\n    Uninstalling urllib3-1.26.18:\n      Successfully uninstalled urllib3-1.26.18\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: orjson\n    Found existing installation: orjson 3.9.10\n    Uninstalling orjson-3.9.10:\n      Successfully uninstalled orjson-3.9.10\n  Attempting uninstall: kubernetes\n    Found existing installation: kubernetes 26.1.0\n    Uninstalling kubernetes-26.1.0:\n      Successfully uninstalled kubernetes-26.1.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.8.1 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.0 which is incompatible.\nbotocore 1.34.34 requires urllib3<2.1,>=1.25.4; python_version >= \"3.10\", but you have urllib3 2.2.1 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.1.2 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nkfp 2.5.0 requires google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0 which is incompatible.\nkfp 2.5.0 requires kubernetes<27,>=8.0.0, but you have kubernetes 29.0.0 which is incompatible.\nkfp 2.5.0 requires urllib3<2.0.0, but you have urllib3 2.2.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed asgiref-3.7.2 bcrypt-4.1.2 build-1.1.1 chroma-hnswlib-0.7.3 chromadb-0.4.24 coloredlogs-15.0.1 humanfriendly-10.0 jq-1.6.0 kubernetes-29.0.0 langchain-0.1.10 langchain-community-0.0.25 langchain-core-0.1.28 langchain-openai-0.0.8 langchain-text-splitters-0.0.1 langchainhub-0.1.14 langsmith-0.1.13 monotonic-1.6 onnxruntime-1.17.1 openai-1.13.3 opentelemetry-instrumentation-0.43b0 opentelemetry-instrumentation-asgi-0.43b0 opentelemetry-instrumentation-fastapi-0.43b0 opentelemetry-util-http-0.43b0 orjson-3.9.15 packaging-23.2 posthog-3.4.2 pulsar-client-3.4.0 pypika-0.48.9 pyproject_hooks-1.0.0 tiktoken-0.6.0 types-requests-2.31.0.20240218 urllib3-2.1.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# ChatBot Without Memory","metadata":{}},{"cell_type":"markdown","source":"## Code to Initialize Chatbot","metadata":{}},{"cell_type":"code","source":"from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_community.document_loaders import JSONLoader\nfrom langchain_community.embeddings import OpenAIEmbeddings\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnableLambda, RunnablePassthrough\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain import hub\nfrom langchain.retrievers.multi_query import MultiQueryRetriever\nimport os\n\nos.environ[\"OPENAI_API_KEY\"] = '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'\n\ndef split_docs(documents,chunk_size=1000,chunk_overlap=100):\n    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n    docs = text_splitter.split_documents(documents)\n    return docs\n\nembedding_function = OpenAIEmbeddings()\n\n\nloader = JSONLoader(file_path=\"/kaggle/input/data-articles-qa/data.json\", jq_schema=\".[]\", text_content=False)\n\ndocuments = loader.load()\n\ndocs = split_docs(documents)\n\nllm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature = 0)\n\ndb = Chroma.from_documents(documents=docs, embedding=embedding_function)\n\nretriever = db.as_retriever()\n\nretriever_from_llm = MultiQueryRetriever.from_llm(\n    retriever=retriever, llm=llm\n)\n\n\nprompt = hub.pull(\"rlm/rag-prompt\")\n\n\ndef format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)\n\n\nrag_chain = (\n    {\"context\": retriever_from_llm | format_docs, \"question\": RunnablePassthrough()}\n    | prompt\n    | llm\n    | StrOutputParser()\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-02T05:23:00.435199Z","iopub.execute_input":"2024-03-02T05:23:00.435624Z","iopub.status.idle":"2024-03-02T05:25:29.830935Z","shell.execute_reply.started":"2024-03-02T05:23:00.435584Z","shell.execute_reply":"2024-03-02T05:25:29.828897Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Validation and Feedback Loop","metadata":{}},{"cell_type":"code","source":"def validate_response(question, response, trusted_sources):\n    # Logic to validate the response\n    # For example, check if key facts in the response match those in trusted_sources\n    \n    prompt = ChatPromptTemplate.from_template(\"\"\" You are good at validating a response by comparing it\\\n    to the context provided. Validate the response by comparing it to the provided context and return 'True'\\\n    if it is valid otherwise return 'False'.\n    \n    context: {context}\n    \n    response: {response}\n    \n    \"\"\")\n    model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n    output_parser = StrOutputParser()\n    \n    context = trusted_sources.get_relevant_documents(question)\n\n#     print(context[1])\n#     print()\n#     print(response)\n    \n    chain = {\"context\": retriever_from_llm | format_docs, \"response\": RunnablePassthrough()} | prompt | model | output_parser\n\n    result = chain.invoke(response)\n    \n#     print(result)\n    \n    \n    if \"True\" in result:\n        is_valid = True\n    elif \"False\" in result:\n        is_valid = False\n        \n    return is_valid\n","metadata":{"execution":{"iopub.status.busy":"2024-03-02T05:51:19.688454Z","iopub.execute_input":"2024-03-02T05:51:19.688903Z","iopub.status.idle":"2024-03-02T05:51:19.698367Z","shell.execute_reply.started":"2024-03-02T05:51:19.688871Z","shell.execute_reply":"2024-03-02T05:51:19.697100Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"## Code to send User query to ChatBot","metadata":{}},{"cell_type":"code","source":"query = \"What are the most sustainable fabric options available for clothing?\"\nanswer = rag_chain.invoke(query)\nprint(answer)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T05:27:38.899339Z","iopub.execute_input":"2024-03-02T05:27:38.899911Z","iopub.status.idle":"2024-03-02T05:27:42.433299Z","shell.execute_reply.started":"2024-03-02T05:27:38.899870Z","shell.execute_reply":"2024-03-02T05:27:42.431445Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"The most sustainable fabric options available for clothing include organic hemp, organic linen, recycled cotton, recycled wool, organic cotton, TENCEL, and Monocel. Lower-impact materials are recommended, such as recycled cotton, recycled wool, organic hemp, or organic linen. Choosing biodegradable fabrics like linen and avoiding synthetic materials like polyester can also contribute to sustainability in clothing choices.\n","output_type":"stream"}]},{"cell_type":"code","source":"Validation_result = validate_response(query,answer,retriever_from_llm)\n\nif Validation_result == False:\n    response = \"I'm not sure about that. Let me get more information and get back to you\"","metadata":{"execution":{"iopub.status.busy":"2024-03-02T05:41:25.819534Z","iopub.execute_input":"2024-03-02T05:41:25.820651Z","iopub.status.idle":"2024-03-02T05:41:30.899140Z","shell.execute_reply.started":"2024-03-02T05:41:25.820596Z","shell.execute_reply":"2024-03-02T05:41:30.897904Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"page_content='natural fibres. The claim that \\\\u201cnatural\\\\u201d fabrics are always best for the environment is questionable at best, as every fabric has its pros and cons, though there are of course better options.\\\\nBeyond that, there\\\\u2019s little chance that brands and shoppers are going to abandon synthetics anytime soon. For some products, like swimwear and rainproof outerwear, synthetic material is just way more practical and the best option we currently have.\\\\nSo what can we do to reduce microfibre pollution in the ocean and the air?\\\\nNow that we\\\\u2019ve covered the background, it\\\\u2019s time to get practical. Let\\\\u2019s look at what to do about microfibres in clothing on a case by case basis.\\\\nBuy less (new) stuff\\\\nThe number one way to reduce the environmental impact of our clothing choices is to buy less stuff, especially less new stuff. Consider spending (less) of your hard-earned dollars on second hand clothing to extend the life of fabrics already in existence.\\\\nCheck out The Five Rs' metadata={'seq_num': 34, 'source': '/kaggle/input/data-articles-qa/data.json'}\n\nThe most sustainable fabric options available for clothing include organic hemp, organic linen, recycled cotton, recycled wool, organic cotton, TENCEL, and Monocel. Lower-impact materials are recommended, such as recycled cotton, recycled wool, organic hemp, or organic linen. Choosing biodegradable fabrics like linen and avoiding synthetic materials like polyester can also contribute to sustainability in clothing choices.\nTrue\n(True, 'The most sustainable fabric options available for clothing include organic hemp, organic linen, recycled cotton, recycled wool, organic cotton, TENCEL, and Monocel. Lower-impact materials are recommended, such as recycled cotton, recycled wool, organic hemp, or organic linen. Choosing biodegradable fabrics like linen and avoiding synthetic materials like polyester can also contribute to sustainability in clothing choices.')\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# ChatBot with Memory Storage","metadata":{}},{"cell_type":"markdown","source":"## Code to Initialize Chatbot","metadata":{}},{"cell_type":"code","source":"from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\nfrom langchain_community.vectorstores import Chroma\nfrom langchain_community.document_loaders import JSONLoader\nfrom langchain_community.embeddings import OpenAIEmbeddings\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain_core.runnables import RunnableLambda, RunnablePassthrough\nfrom langchain_openai import ChatOpenAI, OpenAIEmbeddings\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain_core.output_parsers import StrOutputParser\nfrom langchain import hub\nfrom langchain.retrievers.multi_query import MultiQueryRetriever\nfrom langchain_core.messages import AIMessage, HumanMessage\nimport os\n\n#Add OpenAI key\nos.environ[\"OPENAI_API_KEY\"] = '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'\n#Add your filepath\nfile_path = \"/kaggle/input/data-articles-qa/data.json\"\n\ndef split_docs(documents,chunk_size=1000,chunk_overlap=100):\n    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n    docs = text_splitter.split_documents(documents)\n    return docs\n\nembedding_function = OpenAIEmbeddings()\n\n\nloader = JSONLoader(file_path=file_path, jq_schema=\".[]\", text_content=False)\n\ndocuments = loader.load()\n\ndocs = split_docs(documents)\n\nllm = ChatOpenAI(model_name=\"gpt-3.5-turbo-0125\", temperature = 0)\n\ndb = Chroma.from_documents(documents=docs, embedding=embedding_function)\n\nretriever = db.as_retriever()\n\nretriever_from_llm = MultiQueryRetriever.from_llm(\n    retriever=retriever, llm=llm\n)\n\n\nqa_system_prompt = \"\"\"You are an assistant for question-answering tasks. \\\nUse the following pieces of retrieved context to answer the question. \\\nIf you don't know the answer, just say that you don't know. \\\nUse three sentences maximum and keep the answer concise.\\\n\n{context}\"\"\"\nqa_prompt = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", qa_system_prompt),\n        MessagesPlaceholder(variable_name=\"chat_history\"),\n        (\"human\", \"{question}\"),\n    ]\n)\n\ncontextualize_q_system_prompt = \"\"\"Given a chat history and the latest user question \\\nwhich might reference context in the chat history, formulate a standalone question \\\nwhich can be understood without the chat history. Do NOT answer the question, \\\njust reformulate it if needed and otherwise return it as is.\"\"\"\ncontextualize_q_prompt = ChatPromptTemplate.from_messages(\n    [\n        (\"system\", contextualize_q_system_prompt),\n        MessagesPlaceholder(variable_name=\"chat_history\"),\n        (\"human\", \"{question}\"),\n    ]\n)\ncontextualize_q_chain = contextualize_q_prompt | llm | StrOutputParser()\n\ndef format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)\n\ndef contextualized_question(input: dict):\n    if input.get(\"chat_history\"):\n        return contextualize_q_chain\n    else:\n        return input[\"question\"]\n\n\nrag_chain = (\n    RunnablePassthrough.assign(\n        context=contextualized_question | retriever_from_llm | format_docs\n    )\n    | qa_prompt\n    | llm\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T05:47:58.001076Z","iopub.execute_input":"2024-03-02T05:47:58.001543Z","iopub.status.idle":"2024-03-02T05:50:10.669177Z","shell.execute_reply.started":"2024-03-02T05:47:58.001509Z","shell.execute_reply":"2024-03-02T05:50:10.667839Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"## Code to send User query to ChatBot","metadata":{}},{"cell_type":"code","source":"from langchain_core.messages import AIMessage, HumanMessage\nchat_history = []\n\nquery = \"What are the most sustainable fabric options available for clothing?\"\nai_msg = rag_chain.invoke({\"question\": query, \"chat_history\": chat_history})\n\n\nValidation_result = validate_response(query,ai_msg.content,retriever_from_llm)\n\nif Validation_result == False:\n    response = \"I'm not sure about that. Let me get more information and get back to you\"\nelse:\n    print(ai_msg.content)\n    chat_history.extend([HumanMessage(content=query), ai_msg])\n# print(chat_history)","metadata":{"execution":{"iopub.status.busy":"2024-03-02T05:51:47.339376Z","iopub.execute_input":"2024-03-02T05:51:47.339931Z","iopub.status.idle":"2024-03-02T05:51:55.896131Z","shell.execute_reply.started":"2024-03-02T05:51:47.339891Z","shell.execute_reply":"2024-03-02T05:51:55.894613Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"The most sustainable fabric options for clothing include recycled cotton, recycled wool, organic hemp, and organic linen. These materials have lower environmental impacts compared to conventional options like conventional cotton or virgin polyester. Choosing biodegradable fabrics like linen can also contribute to sustainability in fashion.\n","output_type":"stream"}]},{"cell_type":"code","source":"second_question = \"can you mention some companies that use these materials\"\nai_msg2 = rag_chain.invoke({\"question\": second_question, \"chat_history\": chat_history})\n\nValidation_result = validate_response(second_question,ai_msg2.content,retriever_from_llm)\n\nif Validation_result == False:\n    response = \"I'm not sure about that. Let me get more information and get back to you\"\n    \nelse:\n    print(ai_msg2.content)  ","metadata":{"execution":{"iopub.status.busy":"2024-03-02T05:52:02.342291Z","iopub.execute_input":"2024-03-02T05:52:02.342679Z","iopub.status.idle":"2024-03-02T05:52:13.926099Z","shell.execute_reply.started":"2024-03-02T05:52:02.342651Z","shell.execute_reply":"2024-03-02T05:52:13.924576Z"},"trusted":true},"execution_count":40,"outputs":[{"name":"stdout","text":"Major brands like Adidas, ASOS, H&M, and Burberry have pledged to use 100% sustainable cotton by 2025. New technologies like blockchain are also being used to trace cotton supply chains and ensure ethical and sustainable practices. Additionally, brands like Afends, Mila.Vert, and Natasha Tonic are known for making sustainable hemp clothing that is on-trend and eco-friendly.\n","output_type":"stream"}]}]}