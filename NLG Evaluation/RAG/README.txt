
README.TXT
---
This folder contains a comprehensive set of files pertaining to Retriever-Augmented Generation (RAG) evaluation. These Natural Language Generation (NLG) models are assessed on their performance in generating relevant and informative text. The main focus is to compare the outputs from these models across various metrics and samples.

Contents:

Jupyter Notebook
Jupyter Notebook containing the evaluation code and results for the RAG model. This includes performance metrics, analysis, and visual representations of the model’s output.

Candidates.txt
Text file listing generated responses from both models for various input queries. This file serves as raw data for analyzing the text generation capabilities of each model.

References.txt
A text file containing reference texts is used as a standard to compare against the models’ generated responses. These references help assess the relevance and accuracy of the output.

Results.xlsx
Excel spreadsheet that summarizes the evaluation results, including scores and statistical analyses, providing a quick overview of the comparative performance of the models.
