{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "362e7836",
      "metadata": {
        "id": "362e7836"
      },
      "source": [
        "# Importing Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d492oFyGEpyx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d492oFyGEpyx",
        "outputId": "6a0eeca2-05b6-4f81-b785-1f7f3ed32a47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3f1ad633",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f1ad633",
        "outputId": "7a4205f4-f7be-4b6d-c87f-a89834af72a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n"
          ]
        }
      ],
      "source": [
        "!pip install contractions\n",
        "# apt install python3-contractions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f7e38af5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7e38af5",
        "outputId": "891496ab-2e86-45c9-d148-7d9c239e185b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ad6484b9",
      "metadata": {
        "id": "ad6484b9"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "import json\n",
        "import re\n",
        "import csv\n",
        "import string\n",
        "import json\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import unicodedata\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "import contractions\n",
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0eb82381",
      "metadata": {
        "id": "0eb82381"
      },
      "source": [
        "# Read a dialog file and create a DataFrame of questions and answers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d875839d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "d875839d",
        "outputId": "42da6e48-bfb2-496b-d663-f29b14c44ed7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"# f\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Why is it challenging to find BIPOC owned fashion brands?\",\n          \"What is the message conveyed by the unique collections of BIPOC owned brands?\",\n          \"What is the significance of featuring BIPOC owned brands in content?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"It is challenging to find BIPOC owned fashion brands because the fashion and sustainability spaces are predominantly white-dominated, making it harder for BIPOC owned brands to gain visibility.\",\n          \"The unique collections of BIPOC owned brands convey their individual creative perspectives and cultural influences, showcasing a diverse range of styles and designs within the fashion industry.\",\n          \"Featuring BIPOC owned brands in content is significant as it helps amplify their presence and provides a platform for these brands to reach a wider audience, ultimately supporting their growth and success.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-3e6a1c10-b894-43bb-a564-fcafc4900361\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Why is it important to support BIPOC owned fas...</td>\n",
              "      <td>Supporting BIPOC owned fashion brands is impor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Why is it challenging to find BIPOC owned fash...</td>\n",
              "      <td>It is challenging to find BIPOC owned fashion ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>What is the significance of featuring BIPOC ow...</td>\n",
              "      <td>Featuring BIPOC owned brands in content is sig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>How can supporting BIPOC owned brands contribu...</td>\n",
              "      <td>Supporting BIPOC owned brands is a tangible wa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>What is the message conveyed by the unique col...</td>\n",
              "      <td>The unique collections of BIPOC owned brands c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e6a1c10-b894-43bb-a564-fcafc4900361')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3e6a1c10-b894-43bb-a564-fcafc4900361 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3e6a1c10-b894-43bb-a564-fcafc4900361');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-772e0b57-7106-4d5e-b834-3cdc3934e227\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-772e0b57-7106-4d5e-b834-3cdc3934e227')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-772e0b57-7106-4d5e-b834-3cdc3934e227 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                            question  \\\n",
              "0  Why is it important to support BIPOC owned fas...   \n",
              "1  Why is it challenging to find BIPOC owned fash...   \n",
              "2  What is the significance of featuring BIPOC ow...   \n",
              "3  How can supporting BIPOC owned brands contribu...   \n",
              "4  What is the message conveyed by the unique col...   \n",
              "\n",
              "                                              answer  \n",
              "0  Supporting BIPOC owned fashion brands is impor...  \n",
              "1  It is challenging to find BIPOC owned fashion ...  \n",
              "2  Featuring BIPOC owned brands in content is sig...  \n",
              "3  Supporting BIPOC owned brands is a tangible wa...  \n",
              "4  The unique collections of BIPOC owned brands c...  "
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "question  =[]\n",
        "answer = []\n",
        "# Opening JSON file\n",
        "f = open('/content/drive/MyDrive/data-5.json')\n",
        "\n",
        "# returns JSON object as\n",
        "# a dictionary\n",
        "data = json.load(f)\n",
        "\n",
        "# Iterating through the json\n",
        "# list\n",
        "i=0\n",
        "for i in range(len(data)):\n",
        "    # i+=1\n",
        "    # if i==6:\n",
        "    #         break\n",
        "    for j in data[i][\"Q&As\"]:\n",
        "#         print(type(list(j.values())))\n",
        "        question.append(list(j.values())[0])\n",
        "        answer.append(list(j.values())[1])\n",
        "data = pd.DataFrame({\"question\" : question ,\"answer\":answer})\n",
        "data.head()\n",
        "# Closing file\n",
        "# f.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "417587b5",
      "metadata": {
        "id": "417587b5"
      },
      "source": [
        "# Preprocessing text data using unicode normalization, regular expressions, and string manipulation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2Wid7ktJME9A",
      "metadata": {
        "id": "2Wid7ktJME9A"
      },
      "source": [
        "unicode_to_ascii: This function converts Unicode strings to\n",
        "ASCII, removing diacritics (accents) from characters. This simplification can help reduce the complexity of the dataset for natural language processing.\n",
        "\n",
        "clean_text: This function performs several preprocessing steps on the text: converting to lowercase, removing numbers, expanding contractions, cleaning up various English expressions and removing punctuation. It also wraps sentences with <sos> (start of sentence) and <eos> (end of sentence) tokens, which are common practices in sequence modeling to indicate the beginning and end of sentences.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3cb7e88b",
      "metadata": {
        "id": "3cb7e88b"
      },
      "outputs": [],
      "source": [
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "      if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "def clean_text(text):\n",
        "    text = unicode_to_ascii(text.lower().strip())\n",
        "    text = \" \".join(text.split())\n",
        "    text = ''.join([i for i in text if not i.isdigit()])\n",
        "    contractions.fix(text)\n",
        "    text = re.sub(r\"i'm\", \"i am\", text)\n",
        "    text = re.sub(r\"hi\", \"hey\", text)\n",
        "    text = re.sub(r\"\\r\", \"\", text)\n",
        "    text = re.sub(r\"he's\", \"he is\", text)\n",
        "    text = re.sub(r\"she's\", \"she is\", text)\n",
        "    text = re.sub(r\"it's\", \"it is\", text)\n",
        "    text = re.sub(r\"that's\", \"that is\", text)\n",
        "    text = re.sub(r\"what's\", \"that is\", text)\n",
        "    text = re.sub(r\"where's\", \"where is\", text)\n",
        "    text = re.sub(r\"how's\", \"how is\", text)\n",
        "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
        "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"\\'d\", \" would\", text)\n",
        "    text = re.sub(r\"\\'re\", \" are\", text)\n",
        "    text = re.sub(r\"won't\", \"will not\", text)\n",
        "    text = re.sub(r\"can't\", \"cannot\", text)\n",
        "    text = re.sub(r\"n't\", \" not\", text)\n",
        "    text = re.sub(r\"n'\", \"ng\", text)\n",
        "    text = re.sub(r\"'bout\", \"about\", text)\n",
        "    text = re.sub(r\"'til\", \"until\", text)\n",
        "    text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = re.sub(\"(\\\\W)\",\" \",text)\n",
        "    text = re.sub('\\S*\\d\\S*\\s*','', text)\n",
        "    text =  \"<sos> \" +  text + \" <eos>\"\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b378fbf",
      "metadata": {
        "id": "0b378fbf"
      },
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70d8f3ae",
      "metadata": {
        "id": "70d8f3ae"
      },
      "source": [
        "# Clean, Convert, & Tokenize the data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LAzslJTcMWkS",
      "metadata": {
        "id": "LAzslJTcMWkS"
      },
      "source": [
        "This cell applies the clean_text function to the questions and answers to prepare them for the model. It then tokenizes the cleaned text, converting each word to a numerical index. Tokenization is crucial for neural networks since they require numerical input. The data is also padded to ensure that all sequences are the same length, which is necessary for batch processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5085487d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5085487d",
        "outputId": "70f80d8f-31b2-4850-f5d1-c2b424dc6c7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3945\n"
          ]
        }
      ],
      "source": [
        "data[\"question\"] = data.question.apply(clean_text)\n",
        "data[\"answer\"] = data.answer.apply(clean_text)\n",
        "question  = data.question.values.tolist()\n",
        "answer =  data.answer.values.tolist()\n",
        "\n",
        "def tokenize(lang):\n",
        "    lang_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
        "    lang_tokenizer.fit_on_texts(lang)\n",
        "    tensor = lang_tokenizer.texts_to_sequences(lang)\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
        "    return tensor, lang_tokenizer\n",
        "print(len(data[\"question\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jcLDjWcYM_Os",
      "metadata": {
        "id": "jcLDjWcYM_Os"
      },
      "source": [
        "# Setting up data for sequence-to-sequence model training!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39f57929",
      "metadata": {
        "id": "39f57929"
      },
      "source": [
        "Here, we perform various data preprocessing steps like tokenization, removal of start and end tags, and creation of training and validation datasets using an 80-20 split. The tokenization process involves creating word-to-index and index-to-word dictionaries for both input and target languages. We can also set various hyperparameters for the model like the embedding dimension, number of units, vocabulary size, batch size, and buffer size.`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6e71c2b9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e71c2b9",
        "outputId": "344f51fb-de1f-432e-d205-2f16f78a7f62",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28 <keras.src.preprocessing.text.Tokenizer object at 0x7be0c0c23580> [[   3  116 1702 ...    0    0    0]\n",
            " [   3   20    9 ...    0    0    0]\n",
            " [   3 1248 1702 ...    0    0    0]\n",
            " ...\n",
            " [   3  750  746 ...    0    0    0]\n",
            " [   3  750  746 ...    0    0    0]\n",
            " [   3  750  746 ...    0    0    0]] <keras.src.preprocessing.text.Tokenizer object at 0x7be0a6532320>\n"
          ]
        }
      ],
      "source": [
        "input_tensor , inp_lang  =  tokenize(question)\n",
        "target_tensor , targ_lang  =  tokenize(answer)\n",
        "\n",
        "def remove_tags(sentence):\n",
        "    return sentence.split(\"<start>\")[-1].split(\"<end>\")[0]\n",
        "\n",
        "max_length_targ, max_length_inp = target_tensor.shape[1], input_tensor.shape[1]\n",
        "\n",
        "# Creating training and validation sets using an 80-20 split\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\n",
        "\n",
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 1\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\n",
        "embedding_dim =256\n",
        "units = 1024\n",
        "vocab_inp_size = len(inp_lang.word_index)+1\n",
        "vocab_tar_size = len(targ_lang.word_index)+1\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "example_input_batch.shape, example_target_batch.shape\n",
        "\n",
        "print((input_tensor[0][3]) , inp_lang ,target_tensor , targ_lang)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d90fb8a4",
      "metadata": {
        "id": "d90fb8a4"
      },
      "source": [
        "# Encoder class for Sequence-to-Sequence model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pBl1zAMLNPhF",
      "metadata": {
        "id": "pBl1zAMLNPhF"
      },
      "source": [
        "Defines the Encoder class as part of the Seq2Seq model. It uses an Embedding layer to convert token indices into dense vectors of fixed size and a GRU layer to process the sequence input. The GRU (Gated Recurrent Unit) is a type of RNN (Recurrent Neural Network) architecture."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b9f060ff",
      "metadata": {
        "id": "b9f060ff"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.enc_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True,\n",
        "                                       recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, x,hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state = hidden)\n",
        "        return output, state\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aeb4eba1",
      "metadata": {
        "id": "aeb4eba1"
      },
      "source": [
        "# Encoder Model Initialization and Output Shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2zEYkfMBNlNB",
      "metadata": {
        "id": "2zEYkfMBNlNB"
      },
      "source": [
        "This cell instantiates the Encoder with the specified vocabulary size, embedding dimension, units, and batch size. It initializes the hidden state and then passes a sample input batch through the encoder to test it. The shapes of the output and hidden state are printed to verify the dimensions, which is essential for debugging and ensuring the model components interact as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "dfc8c18c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfc8c18c",
        "outputId": "c6c507a8-fc77-4b0a-93b7-cd23bda7a72a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (1, 30, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (1, 1024)\n"
          ]
        }
      ],
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "# sample input\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1a69e1d",
      "metadata": {
        "id": "f1a69e1d"
      },
      "source": [
        "# Bahdanau Attention Layer Implementation for Neural Machine Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "566dced4",
      "metadata": {
        "id": "566dced4"
      },
      "source": [
        "The code defines a custom Keras layer that implements Bahdanau attention mechanism for Neural Machine Translation. Bahdanau attention is a type of attention mechanism that computes attention weights over the input sequence at every time step, and generates a context vector that is a weighted sum of the input sequence. This context vector is then used by the decoder to generate the output sequence. The implementation uses two dense layers, W1 and W2, to map the input and query to a common hidden space, and a dense layer V to generate the attention weights. The layer takes as input the query (decoder hidden state) and the values (encoder output sequence), and outputs the context vector and attention weights.`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "40ecad4d",
      "metadata": {
        "id": "40ecad4d"
      },
      "outputs": [],
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        self.W1 = tf.keras.layers.Dense(units)\n",
        "        self.W2 = tf.keras.layers.Dense(units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        # query hidden state shape == (batch_size, hidden size)\n",
        "        # query_with_time_axis shape == (batch_size, 1, hidden size)\n",
        "        # values shape == (batch_size, max_len, hidden size)\n",
        "        # we are doing this to broadcast addition along the time axis to calculate the score\n",
        "        query_with_time_axis = tf.expand_dims(query, 1)\n",
        "\n",
        "        # score shape == (batch_size, max_length, 1)\n",
        "        # we get 1 at the last axis because we are applying score to self.V\n",
        "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\n",
        "        score = self.V(tf.nn.tanh(\n",
        "            self.W1(query_with_time_axis) + self.W2(values)))\n",
        "\n",
        "        # attention_weights shape == (batch_size, max_length, 1)\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "#         print(\"attention_weights : \",attention_weights)\n",
        "\n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\n",
        "        context_vector = attention_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f5d61ce6",
      "metadata": {
        "id": "f5d61ce6"
      },
      "source": [
        "# Applying Bahdanau Attention to Encoder Outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9b47f82",
      "metadata": {
        "id": "f9b47f82"
      },
      "source": [
        "Here, an instance of the BahdanauAttention class is created and tested with sample data. This piece of code demonstrates how the attention mechanism can be applied to the hidden state and output of the encoder, showing the dimensions of the resulting context vector and attention weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "0619ac2d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0619ac2d",
        "outputId": "4d465b66-22e1-4113-d68f-0c3dedfdc085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (1, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (1, 30, 1)\n"
          ]
        }
      ],
      "source": [
        "attention_layer = BahdanauAttention(10)\n",
        "attention_result, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cc539491",
      "metadata": {
        "id": "cc539491"
      },
      "source": [
        "#A decoder class that takes the output from the encoder and generates the target sequence word by word!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdc2eeba",
      "metadata": {
        "id": "cdc2eeba"
      },
      "source": [
        "The Decoder class is a sub-class of the tf.keras.Model class, which defines the decoding part of the Sequence-to-Sequence model used for the chatbot. The decoder is responsible for generating the output sequence given the encoded input sequence and the previous state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e2650371",
      "metadata": {
        "id": "e2650371"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.dec_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True,\n",
        "                                       recurrent_initializer='glorot_uniform')\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "        # used for attention\n",
        "        self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
        "        context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "\n",
        "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "        # passing the concatenated vector to the GRU\n",
        "        output, state = self.gru(x)\n",
        "\n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "        # output shape == (batch_size, vocab)\n",
        "        x = self.fc(output)\n",
        "\n",
        "        return x, state, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bf277fc",
      "metadata": {
        "id": "2bf277fc"
      },
      "source": [
        "# Decoder model initialization and sample output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d5317a7",
      "metadata": {
        "id": "7d5317a7"
      },
      "source": [
        "This cell initializes the decoder with the specified parameters and tests it using a sample input, a hidden state, and encoder output. The shape of the decoder output is printed to ensure it's correct; this output represents the probability distribution over the target vocabulary for each batch item."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "c4389eb7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4389eb7",
        "outputId": "2eafbfcd-b528-4b0e-fca2-1a09722473ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (1, 8650)\n"
          ]
        }
      ],
      "source": [
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd7724e2",
      "metadata": {
        "id": "bd7724e2"
      },
      "source": [
        "# Loss function using Adam optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4ad0fa87",
      "metadata": {
        "id": "4ad0fa87"
      },
      "source": [
        "Sets up the optimizer and loss function for training the Seq2Seq model. The Adam optimizer is used for its efficiency with large datasets and parameter spaces. The loss function is defined to handle sequence prediction, ignoring padding tokens in the loss calculation to prevent them from affecting the model's learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "dbab8b2c",
      "metadata": {
        "id": "dbab8b2c"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "#     print(\"real : \",real,\"\\npredicted : \",pred)\n",
        "#     print (\"loss_ : \",loss_)\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "edad26ce",
      "metadata": {
        "id": "edad26ce"
      },
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea9a0607",
      "metadata": {
        "id": "ea9a0607"
      },
      "source": [
        "# Training Step Function using Teacher Forcing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "8446a483",
      "metadata": {
        "id": "8446a483"
      },
      "outputs": [],
      "source": [
        "@tf.function\n",
        "def train_step(inp, targ, enc_hidden,variables=np.array([]),gradients=np.array([])):#,variables=np.array([])\n",
        "    loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "\n",
        "        dec_hidden = enc_hidden\n",
        "\n",
        "        dec_input = tf.expand_dims([targ_lang.word_index['<sos>']] * BATCH_SIZE, 1)\n",
        "\n",
        "        # Teacher forcing - feeding the target as the next input\n",
        "        for t in range(1, targ.shape[1]):\n",
        "            # passing enc_output to the decoder\n",
        "            predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "            loss += loss_function(targ[:, t], predictions)\n",
        "#             print(\"loss : \",loss)\n",
        "            # using teacher forcing\n",
        "            dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "#     if len(variables)<=0:\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "#     print(\"variables : \",variables)\n",
        "#     print(\"vrb : \",vrb)\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "\n",
        "#     print(\"gradients : \",gradients)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss, variables,gradients"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b82284c",
      "metadata": {
        "id": "8b82284c"
      },
      "source": [
        "#Training loop for the Chatbot Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd09dfa1",
      "metadata": {
        "id": "dd09dfa1"
      },
      "source": [
        "\n",
        "The training loop iterates over the dataset for a number of epochs, calling the training step function for each batch. It often tracks the loss and sometimes other metrics, printing them out or logging them for monitoring. This loop is where the actual learning occurs, as the model's weights are adjusted to minimize the loss on the training data.\n",
        "It appears that the loss decreases with each epoch, which suggests that the model is improving and learning to generate more accurate translations. The decreasing loss values are also a good sign that the optimizer and loss function are appropriate for the task at hand.`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "d0zsy8T5BebE",
      "metadata": {
        "id": "d0zsy8T5BebE"
      },
      "outputs": [],
      "source": [
        "# Run it first time\n",
        "vrb=grd=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "ZrVRvpJCBXPh",
      "metadata": {
        "id": "ZrVRvpJCBXPh"
      },
      "outputs": [],
      "source": [
        "# run it other times\n",
        "vrb=pd.read_pickle(\"/content/drive/MyDrive/vrb.pkl\")\n",
        "grd=pd.read_pickle(\"/content/drive/MyDrive/grd.pkl\")\n",
        "# pd.read_pickle(\"grd.npy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "rKSALV2HBihM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKSALV2HBihM",
        "outputId": "249dcf2b-686a-4cc3-b472-e9ae40456994"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "Epoch:  1 Loss:2.0835\n",
            "2\n",
            "Epoch:  2 Loss:1.9568\n",
            "3\n",
            "Epoch:  3 Loss:1.7613\n",
            "4\n",
            "Epoch:  4 Loss:1.6017\n",
            "5\n",
            "Epoch:  5 Loss:1.4410\n",
            "6\n",
            "Epoch:  6 Loss:1.2772\n",
            "7\n",
            "Epoch:  7 Loss:1.1160\n",
            "8\n",
            "Epoch:  8 Loss:0.9603\n",
            "9\n",
            "Epoch:  9 Loss:0.8127\n",
            "10\n",
            "Epoch: 10 Loss:0.6790\n",
            "11\n",
            "Epoch: 11 Loss:0.5611\n",
            "12\n",
            "Epoch: 12 Loss:0.4618\n",
            "13\n",
            "Epoch: 13 Loss:0.3807\n",
            "14\n",
            "Epoch: 14 Loss:0.3125\n",
            "15\n",
            "Epoch: 15 Loss:0.2607\n",
            "16\n",
            "Epoch: 16 Loss:0.2204\n",
            "17\n",
            "Epoch: 17 Loss:0.1880\n",
            "18\n",
            "Epoch: 18 Loss:0.1647\n",
            "19\n",
            "Epoch: 19 Loss:0.1453\n",
            "20\n",
            "Epoch: 20 Loss:0.1312\n",
            "21\n",
            "Epoch: 21 Loss:0.1212\n",
            "22\n",
            "Epoch: 22 Loss:0.1116\n",
            "23\n",
            "Epoch: 23 Loss:0.1023\n",
            "24\n",
            "Epoch: 24 Loss:0.0991\n",
            "25\n",
            "Epoch: 25 Loss:0.0943\n",
            "26\n",
            "Epoch: 26 Loss:0.0894\n",
            "27\n",
            "Epoch: 27 Loss:0.0853\n",
            "28\n",
            "Epoch: 28 Loss:0.0822\n",
            "29\n",
            "Epoch: 29 Loss:0.0798\n",
            "30\n",
            "Epoch: 30 Loss:0.0775\n",
            "31\n",
            "Epoch: 31 Loss:0.0740\n",
            "32\n",
            "Epoch: 32 Loss:0.0715\n",
            "33\n",
            "Epoch: 33 Loss:0.0704\n",
            "34\n",
            "Epoch: 34 Loss:0.0690\n",
            "35\n",
            "Epoch: 35 Loss:0.0660\n",
            "36\n",
            "Epoch: 36 Loss:0.0651\n",
            "37\n",
            "Epoch: 37 Loss:0.0645\n",
            "38\n",
            "Epoch: 38 Loss:0.0619\n",
            "39\n",
            "Epoch: 39 Loss:0.0594\n",
            "40\n",
            "Epoch: 40 Loss:0.0600\n",
            "41\n",
            "Epoch: 41 Loss:0.0590\n",
            "42\n",
            "Epoch: 42 Loss:0.0565\n",
            "43\n",
            "Epoch: 43 Loss:0.0562\n",
            "44\n",
            "Epoch: 44 Loss:0.0566\n",
            "45\n",
            "Epoch: 45 Loss:0.0531\n",
            "46\n",
            "Epoch: 46 Loss:0.0561\n",
            "47\n",
            "Epoch: 47 Loss:0.0523\n",
            "48\n",
            "Epoch: 48 Loss:0.0493\n",
            "49\n",
            "Epoch: 49 Loss:0.0509\n",
            "50\n",
            "Epoch: 50 Loss:0.0513\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    print(epoch)\n",
        "    enc_hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\n",
        "        batch_loss,vrb,grd = train_step(inp, targ, enc_hidden,vrb,grd)#,vrb,grd\n",
        "        total_loss += batch_loss\n",
        "    df1=pd.Series(vrb)\n",
        "    df1.to_pickle(\"vrb.pkl\")\n",
        "\n",
        "    df2=pd.DataFrame(grd)\n",
        "    df2.to_pickle(\"grd.pkl\")\n",
        "    print('Epoch:{:3d} Loss:{:.4f}'.format(epoch,\n",
        "                                          total_loss / steps_per_epoch))\n",
        "\n",
        "\n",
        "#         np.save(f, )\n",
        "\n",
        "#     if(epoch % 2 == 0):\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "XI-CijfMZ9W1",
      "metadata": {
        "id": "XI-CijfMZ9W1"
      },
      "outputs": [],
      "source": [
        "# With this line:\n",
        "encoder.save('/content/drive/MyDrive/model_state_final', save_format='tf')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35fed4ce",
      "metadata": {
        "id": "35fed4ce"
      },
      "source": [
        "# Evaluation function for the Chatbot Model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4832f9d5",
      "metadata": {
        "id": "4832f9d5"
      },
      "source": [
        "An evaluation function is used to test the chatbot's performance on unseen data. It's similar to the training function but without the backpropagation step—no weights are updated. The function typically runs the model on a set of questions and generates responses, then compares these generated responses to the actual answers. This function helps gauge how well the model is learning and generalizing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "11a3889b",
      "metadata": {
        "id": "11a3889b"
      },
      "outputs": [],
      "source": [
        "def evaluate(sentence):\n",
        "    sentence = clean_text(sentence)\n",
        "    try:\n",
        "        inputs = [inp_lang.word_index[i] for i in sentence.split(' ')]\n",
        "    except:\n",
        "        return \"I am sorry, I dont have the appropriate answer for you at this time\",sentence\n",
        "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs],\n",
        "                                                         maxlen=max_length_inp,\n",
        "                                                         padding='post')\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<sos>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\n",
        "                                                             dec_hidden,\n",
        "                                                             enc_out)\n",
        "\n",
        "        # storing the attention weights to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang.index_word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang.index_word[predicted_id] == '<eos>':\n",
        "            return remove_tags(result), remove_tags(sentence)\n",
        "\n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return remove_tags(result), remove_tags(sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faacc1b8",
      "metadata": {
        "id": "faacc1b8"
      },
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56dee762",
      "metadata": {
        "id": "56dee762"
      },
      "source": [
        "# Loading and using our Chatbot model to answer questions!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cdd1cc3e",
      "metadata": {
        "id": "cdd1cc3e"
      },
      "outputs": [],
      "source": [
        "questions  =[]\n",
        "answers = []\n",
        "# with open(\"dialogs.txt\",'r') as f :\n",
        "#     for line in f :\n",
        "#         line  =  line.split('\\t')\n",
        "#         questions.append(line[0])\n",
        "#         answers.append(line[1])\n",
        "# print(len(question) == len(answer))\n",
        "\n",
        "def ask(sentence):\n",
        "    result, sentence = evaluate(sentence)\n",
        "\n",
        "    print('Question: %s' % (sentence))\n",
        "    print('Predicted answer: {}'.format(result))\n",
        "    return result\n",
        "# ask(questions[10])\n",
        "# print(\"Actual : \")\n",
        "# print(questions[10],\"\\n\",answers[10])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "TbpcBOC0hLpm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TbpcBOC0hLpm",
        "outputId": "0c050290-19cc-4d8e-efb7-73faf4a8d2cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: <sos> what is the most carbonefficient option for sheypping <eos>\n",
            "Predicted answer: transporting goods via boat is the most carbonefficient option currently available a big sheyp emits about grams of carbon dioxide to transport metric ton of cargo kilometer  \n",
            "Question: <sos> what are some tips for switcheyng from fast fasheyon to vintage on instagram <eos>\n",
            "Predicted answer: to make it hard to break up with friends  \n",
            "Question: <sos> is calling out fast fasheyon considered classist <eos>\n",
            "Predicted answer: yes calling out fast fasheyon is often considered classist due to the perception that sustainable fasheyon is often considered classist due to the perception that sustainable fasheyon is often considered classist due to the perception that sustainable fasheyon is often considered classist due to the perception that sustainable fasheyon is often considered classist due to the perception that sustainable fasheyon is often considered classist due to the perception that sustainable fasheyon is often considered classist due to the perception that sustainable fasheyon is often considered classist \n",
            "Question: <sos> how does asics rate in terms of environmental impact <eos>\n",
            "Predicted answer: pullbear is rated not good enough for its environmental impact due to its unsustainable fast fasheyon model  \n",
            "Question: <sos> how does fair trade ensure workers are treated fairly <eos>\n",
            "Predicted answer: fair trade audits working conditions to meet safety and supports workers rights to organize and unionize  \n",
            "Question: <sos> what are some of the etheycal menswear brands stocked by brothers we stand <eos>\n",
            "Predicted answer: some of the etheycal menswear brands stocked by brothers we stand include mud jeans elvis and kresse and ecoalf  \n",
            "Question: <sos> where are the garments from the classic tsheyrt company made <eos>\n",
            "Predicted answer: the garments from the classic tsheyrt company are locally made in california  \n",
            "Question: <sos> where can you find more information about etheycal and sustainable clotheyng brands in other regions <eos>\n",
            "Predicted answer: you can check out the editors favorite brands from various regions including the usa canada europe london australia new zealand and india  \n",
            "Question: <sos> what inspired carlie ballard to start her journey in etheycal fasheyon <eos>\n",
            "Predicted answer: the sustainability of the fasheyon industry to eradicate her personal approach to create the fasheyon industry to eradicate her personal approach to create the fasheyon industry to eradicate her personal approach to create the fasheyon industry to eradicate her personal approach to create the fasheyon industry to eradicate her personal approach to create the fasheyon industry to eradicate her personal approach to create the fasheyon industry to eradicate her personal approach to create the fasheyon industry to eradicate her personal approach to create the fasheyon industry \n",
            "Question: <sos> why do some fast fasheyon brands receive an it is a start rating <eos>\n",
            "Predicted answer: some fast fasheyon brands receive an it is a start rating because they have taken steps towards sustainability such as setting climate change targets offering ecofriendly fabrics or introducing sustainable collections wheyle these steps are harmful fabrics like the fasheyon industry are not sustainable  \n",
            "Question: <sos> what is the importance of using ecofriendly materials in footwear and accessories <eos>\n",
            "Predicted answer: using ecofriendly materials in footwear and accessories helps reduce the environmental impact with innovative materials in footwear and accessories helps reduce the environmental impact with innovative materials in footwear and accessories helps reduce the environmental impact with innovative materials in footwear and accessories helps reduce the environmental impact with innovative materials in footwear and accessories helps reduce the environmental impact with innovative materials in footwear and accessories helps reduce the environmental impact with innovative materials in footwear and accessories helps reduce the environmental impact with innovative \n",
            "Question: <sos> what is the focus of the article <eos>\n",
            "Predicted answer: the article focuses on the new top picks for january from the good enough in the article is on more sustainable and sustainable fasheyon brands that are new to good on you team featuring responsible fasheyon brands that are new to good on you team featuring responsible fasheyon brands that are new to good on you team featuring responsible fasheyon brands that are new to good on you team featuring responsible fasheyon brands that are new to good on you team featuring responsible fasheyon brands that \n",
            "Question: <sos> how many sustainable alternatives to victorias secret are mentioned in the article <eos>\n",
            "Predicted answer: the article mentions sustainable and using a living wage in the article mentions sustainable and using a living wage in the article mentions sustainable and using a living wage in the article mentions sustainable and using a living wage in the article mentions sustainable and using a living wage in the article mentions sustainable and using a living wage in the article mentions sustainable and using a living wage in the article mentions sustainable and using a living wage in the article mentions sustainable and using \n",
            "Question: <sos> how does bhumi contribute to sustainability through their clotheyng range <eos>\n",
            "Predicted answer: bhumi has expanded their clotheyng range by blending natural fibers with new fabrics made from recycled polyester yarn diverting waste from recycled polyester yarn diverting waste from recycled polyester yarn diverting waste from recycled polyester yarn diverting waste from recycled polyester yarn diverting waste from recycled polyester yarn diverting waste from recycled polyester yarn diverting waste from recycled polyester yarn diverting waste from recycled polyester yarn diverting waste from recycled polyester yarn diverting waste from recycled polyester yarn diverting waste from recycled polyester yarn diverting waste \n",
            "Question: <sos> why is good clotheyng care important for the planet <eos>\n",
            "Predicted answer: good clotheyng care for the planet because it helps extend the life of clothes keeping them out of landfills and reducing textile waste  \n",
            "Question: <sos> what are some platforms recommended for buying secondhand clotheyng <eos>\n",
            "Predicted answer: some recommended platforms for buying secondhand clotheyng include vestiaire collective thredup thrift depop and the most sustainable options in fasheyon  \n",
            "Question: <sos> where are saya designs pieces handmade <eos>\n",
            "Predicted answer: saya designs pieces are handmade in bali and artisanal trade  \n",
            "Question: <sos> how does organic cotton farming differ from conventional cotton farming <eos>\n",
            "Predicted answer: organic cotton farming avoids the use of pesticides and genetically modified seeds focuses on environmental sustainability and uses fewer resources compared to conventional cotton farming avoids the use of pesticides and genetically modified seeds focuses on environmental sustainability and uses fewer resources compared to conventional cotton farming avoids the use of pesticides and genetically modified seeds focuses on environmental sustainability and uses fewer resources compared to conventional cotton farming avoids the use of pesticides and genetically modified seeds focuses on environmental sustainability and uses fewer resources \n",
            "Question: <sos> what is fabletics overall rating in terms of etheycs <eos>\n",
            "Predicted answer: fabletics has an overall rating of it is a start in terms of etheycs  \n",
            "Question: <sos> what is kmarts labour rating <eos>\n",
            "Predicted answer: kmarts labour rating is not good enough  \n",
            "Question: <sos> what is the main feature of tentrees newest collection youwear <eos>\n",
            "Predicted answer: youwears main fibre is made from recycled postconsumer garments creating a circular lifecycle and producing less co emissions  \n",
            "Question: <sos> what is the main focus of the article when discussing alternatives to hollister <eos>\n",
            "Predicted answer: the main focus of the brand is on the brand is on the brand is on the brand is on the brand is on the brand is on the brand is on the brand is on the brand is on the brand is on the brand is on the brand is on the brand is on the brand is on the brand is on the brand is on the brand is on the brand is on the brand is on the brand is on the brand \n",
            "Question: <sos> wheych etheycal brands are included in the lineup for the etheycal fasheyon pop up shops <eos>\n",
            "Predicted answer: good on yourated favorites such as article and outland denim are included in the lineup for the etheycal fasheyon pop up shops during new york fasheyon week  \n",
            "Question: <sos> what are key points of circular fasheyon <eos>\n",
            "Predicted answer: benefits of measurements are often associated with logoheavy sweatsheyrts grapheyc pollution through a mix of processing and can end and thrifted pieces reflecting a mix of processing and can end and thrifted pieces reflecting a mix of processing and can end and thrifted pieces reflecting a mix of processing and can end and thrifted pieces reflecting a mix of processing and can end and thrifted pieces reflecting a mix of processing and can end and thrifted pieces reflecting a mix of processing and can end and \n",
            "Question: <sos> what is the signature cut of a classic tsheyrt <eos>\n",
            "Predicted answer: the classic tsheyrt company signature cut is semifitted providing the right amount of fabric around the neck shoulders chest armholes sleeves and length  \n",
            "Question: <sos> what is peloton apparels rating in terms of labour conditions <eos>\n",
            "Predicted answer: peloton apparel receives a rating of havery poor for people due to its lack of evidence of a code of evidence of a code of evidence of a code of evidence of a code of evidence of a code of evidence of a code of evidence of a code of evidence of a code of evidence of a code of evidence of a code of evidence of a code of evidence of a code of evidence of a code of evidence of a code of evidence \n",
            "Question: <sos> what are some of the best newlyrated brands mentioned in the article <eos>\n",
            "Predicted answer: the article mentions some of the best newlyrated brands to fill gaps in your wardrobe  \n",
            "Question: <sos> how can you reduce the environmental impact of clotheyng during the consumer use phase <eos>\n",
            "Predicted answer: you can reduce the environmental impact of clotheyng during the laundering process opting for nonsynthetic fibers and wearing garments at least three times before washeyng unless visibly dirty  \n",
            "Question: <sos> what is the detoxdenim campaign by armedangels <eos>\n",
            "Predicted answer: the detoxdenim campaign by armedangels aims to remove toxic elements from the production process of denim and replace them with lowimpact alternatives  \n",
            "Question: <sos> wheych regions and countries are currently listed with good and great rated brands on good on you for local shopping <eos>\n",
            "Predicted answer: some of the regions and countries listed with good and great rated brands on good on you for local shopping include us specifically la canada australia new zealand europe uk germany france netherlands with more to come  \n",
            "Question: <sos> what are some of the principles that the clean clothes campaign is founded on <eos>\n",
            "Predicted answer: some of the principles include workers right to know about their rights publics right to know about their rights publics right to know about their rights publics right to know about their rights publics right to know about their rights publics right to know about their rights publics right to know about their rights publics right to know about their rights publics right to know about their rights publics right to know about their rights publics right to know about their rights publics right to know \n",
            "Question: <sos> what did the new research conducted by the school of design at the university of leeds find regarding clotheyng durability and price <eos>\n",
            "Predicted answer: price is not an indicator of how long clothes will last  \n",
            "Question: <sos> when was the bluesign standard released and why <eos>\n",
            "Predicted answer: the bluesign standard was released in in response to the chemicals used globally come from the bluesign standard was released in in response to the chemicals used globally come from the bluesign standard was released in in response to the chemicals used globally come from the bluesign standard was released in in response to the chemicals used globally come from the bluesign standard was released in in response to the chemicals used globally come from the bluesign standard was released in in response to the chemicals \n",
            "Question: <sos> what are the flaws in standardised sizing <eos>\n",
            "Predicted answer: the key flaw in standardised sizing systems is not the accuracy of measurements but rather the notion that averaging proportions will still offer a good fit to a wide range of measurements but rather the notion that averaging proportions will still offer a good fit to a wide range of measurements but rather the notion that averaging proportions will still offer a good fit to a wide range of measurements but rather the notion that averaging proportions will still offer a good fit to a wide \n",
            "Question: <sos> wheych brand is specifically mentioned in the article as a pinnacle of californian consciousness and ecologicallyminded fasheyon <eos>\n",
            "Predicted answer: patagonia is specifically mentioned in the article as a pinnacle of californian consciousness and ecologicallyminded fasheyon  \n",
            "Question: <sos> can you provide some examples of polyesterfree activewear picks from toprated brands <eos>\n",
            "Predicted answer: some examples of polyesterfree activewear picks from toprated brands include kacheyna organic cotton yoga hareem trousers rose breezy tank top and motivate fulllength heyghwaist tights  \n",
            "Question: <sos> what is suggested after responsibly donating upcycling mending altering or reselling items you no longer need <eos>\n",
            "Predicted answer: to peruse the preloved marketplace first but sometimes turn to new  \n",
            "Question: <sos> what are the environmental impacts of manufacturing nylon <eos>\n",
            "Predicted answer: the production of nylon creates greenhouse gases requires large amounts of water for cooling fibers and global warming  \n",
            "Question: <sos> what is the ethos of thread harvest according to the new director neridah morris <eos>\n",
            "Predicted answer: the ethos of thread harvest is to provide an opportunity for those who care about style and substance to shop their values  \n",
            "Question: <sos> what is pradas environmental impact rating <eos>\n",
            "Predicted answer: pradas environmental impact rating is not good enough as they do not minimize textile waste implement water reduction initiatives or take meaningful action to eliminate hazardous chemicals  \n",
            "Question: <sos> what is pumas environmental impact rating <eos>\n",
            "Predicted answer: pumas environmental impact rating is it is a start they use some ecofriendly materials and have set targets to reduce greenhouse gas emissions but there are concerns about hazardous chemicals and textile waste in their manufacturing process  \n",
            "Question: <sos> how can decorations from unwanted gifts be repurposed <eos>\n",
            "Predicted answer: decorations can be saved for future use recycled or repurposed into new items like baubles pom poms and paper chains to create environmentally friendly festive cheer  \n",
            "Question: <sos> what is kmarts animal welfare rating <eos>\n",
            "Predicted answer: kmarts animal welfare rating is it is a start  \n",
            "Question: <sos> how does good on you ensure credibility in their recommendations <eos>\n",
            "Predicted answer: good on you ensures credibility by aggregating comprehensive and approve each recommendation  \n",
            "Question: <sos> what certification should one look for in organic cotton garments <eos>\n",
            "Predicted answer: the fasheyon industry  \n",
            "Question: <sos> what are some animalderived materials discussed in the article <eos>\n",
            "Predicted answer: some unetheycal practices  \n",
            "Question: <sos> what is the importance of dressing up for video calls <eos>\n",
            "Predicted answer: dressing up can help in creating a sense of routine and setting a sense of routine and setting a sense of routine and setting a sense of routine and setting a sense of routine and setting a sense of routine and setting a sense of routine and setting a sense of routine and setting a sense of routine and setting a sense of routine and setting a sense of routine and setting a sense of routine and setting a sense of routine and setting a sense \n",
            "Question: <sos> why is it important to address ecoanxiety <eos>\n",
            "Predicted answer: it is important to address ecoanxiety as it contribute towards a healtheyer planet and across the global south to address ecoanxiety as it contribute towards a healtheyer planet and across the global south to address ecoanxiety as it contribute towards a healtheyer planet and across the global south to address ecoanxiety as it contribute towards a healtheyer planet and across the global south to address ecoanxiety as it contribute towards a healtheyer planet and across the global south to address ecoanxiety as it contribute towards a \n",
            "Question: <sos> what values does neu nomads collection embody <eos>\n",
            "Predicted answer: neu nomads collection embodies the brands core values of bringing beautiful staples made responsibly catering to global citizens modern minimalists and conscious consumers  \n",
            "Question: <sos> what makes the anyday rain boot by thesus unique <eos>\n",
            "Predicted answer: the anyday rain boot by thesus is a stylish vegan boot by thesus is a stylish vegan boot by thesus is a stylish vegan boot by thesus is a stylish vegan boot by thesus is a stylish vegan boot by thesus is a stylish vegan boot by thesus is a stylish vegan boot by thesus is a stylish vegan boot by thesus is a stylish vegan boot by thesus is a stylish vegan boot by thesus is a stylish vegan boot by thesus is a stylish \n"
          ]
        }
      ],
      "source": [
        "def calculate_accuracy(correct_answers, predicted_answers):\n",
        "    total = len(correct_answers)\n",
        "    matches = 0\n",
        "    \n",
        "    for correct, predicted in zip(correct_answers, predicted_answers):\n",
        "        # Normalize by converting to lowercase and splitting into words\n",
        "        correct_words = set(correct.strip().lower().split())\n",
        "        predicted_words = set(predicted.strip().lower().split())\n",
        "        \n",
        "        # Check for any common words between the correct and predicted answers\n",
        "        if len(correct_words.intersection(predicted_words)) > 0:\n",
        "            matches += 1\n",
        "    \n",
        "    # Calculate accuracy\n",
        "    accuracy = (matches / total) * 100  # Convert to percentage\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "\n",
        "def main():\n",
        "    # Paths to your files with correct answers and predicted answers\n",
        "    correct_answers_file = '/content/drive/MyDrive/true_answers.txt'\n",
        "    predicted_answers_file = '/content/drive/MyDrive/predicted_answers.txt'\n",
        "\n",
        "    # Read all the correct answers from the file\n",
        "    with open(correct_answers_file, 'r') as ca_file:\n",
        "        correct_answers = [line.strip() for line in ca_file.readlines()]\n",
        "\n",
        "    # Read all the predicted answers for comparison\n",
        "    with open(predicted_answers_file, 'r') as pa_file:\n",
        "        predicted_answers = [line.strip() for line in pa_file.readlines()]\n",
        "\n",
        "    # Ensure the lists are comparable\n",
        "    if len(correct_answers) != len(predicted_answers):\n",
        "        print(\"The number of correct answers and predicted answers do not match.\")\n",
        "        return\n",
        "\n",
        "    calculate_accuracy(correct_answers, predicted_answers)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "\n",
        "#Output - Accuracy:  56.74965892649037"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "spBRfe9W_m2T",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "spBRfe9W_m2T",
        "outputId": "50b40114-0328-46c2-ebba-1d7e172fee68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: <sos> what is louis vuitton known for <eos>\n",
            "Predicted answer: louis vuitton is known for its distinctive monogrammed accessories and clotheyng  \n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'louis vuitton is known for its distinctive monogrammed accessories and clotheyng  '"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ask('What is Louis Vuitton known for?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "ZwmmbPgWSVbE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "ZwmmbPgWSVbE",
        "outputId": "378e8cde-91ed-4561-bfd8-e5a00d3183bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: <sos> what is louis vuitton known for <eos>\n",
            "Predicted answer: louis vuitton is known for its distinctive monogrammed accessories and clotheyng  \n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'louis vuitton is known for its distinctive monogrammed accessories and clotheyng  '"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ask('What is Louis Vuitton known for?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "6d60e326",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "6d60e326",
        "outputId": "bd66e12b-36a6-433d-8ca7-6e303475382d",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: <sos> is fair trade is important <eos>\n",
            "Predicted answer: as it can take care bamboo rayon and resources used as one accessible and the environment by taking care after the environment and promotes sustainable option as it gives and turns them as it gives and turns them as it gives and turns them as it gives and turns them as it gives and turns them as it gives and turns them as it gives and turns them as it gives and turns them as it gives and turns them as it gives and turns them \n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'as it can take care bamboo rayon and resources used as one accessible and the environment by taking care after the environment and promotes sustainable option as it gives and turns them as it gives and turns them as it gives and turns them as it gives and turns them as it gives and turns them as it gives and turns them as it gives and turns them as it gives and turns them as it gives and turns them as it gives and turns them '"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ask('is fair trade is important?')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "njUs7fJ8kd6z",
      "metadata": {
        "id": "njUs7fJ8kd6z"
      },
      "outputs": [],
      "source": [
        "# Define the path to your text file\n",
        "file_path = '/content/drive/MyDrive/extracted_answers.txt'\n",
        "\n",
        "# Read the file and filter out any blank lines\n",
        "with open(file_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "    non_blank_lines = [line for line in lines if line.strip()]\n",
        "\n",
        "# Write the non-blank lines back to the file\n",
        "with open(file_path, 'w') as file:\n",
        "    file.writelines(non_blank_lines)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
